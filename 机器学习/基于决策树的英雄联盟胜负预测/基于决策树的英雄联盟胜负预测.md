# 基于决策树的英雄联盟胜负预测⭐
## 🧰决策树模型的实现（算法框架）
- 根据训练数据构建一颗决策树
- 决策树会逐渐把训练集合分成越来越小的子集
- 当子集纯净后不再分裂
- 或者接受一个不完美的决策
### 🧩ID3
- 自顶向下，贪心算法
- 递归算法
- 核心循环：
  - $A$：下一步 最佳 决策属性

      ***Impurity***(混杂度):
      $\displaystyle Entropt=-\sum_{i}^{}{P(w_i)\log_2P(w_i)}$

      ***IG***(信息增益) 
      $\displaystyle Gain(S,A)=Entropy(S)-\sum_{v\in{Values(A)}}^{}{\frac{|S_v|}{|S|}Entropy(S_v)}$

  - 将 $A$ 作为当前节点决策属性
  - 对 $A(v_i)$ 的每个值，创建与其对应的新的子节点
  - 根据属性值将训练样本分配到各个节点
  - 如果 训练样本被完美分类 ，则退出循环，否则继续下探分裂新的叶节点

      **相同的输出类别** 或 **相同的输入类别**
## 🧠构建决策树（代码思路）
1. 创建节点Node类
   - 属性
     - 数据子集x特征，y标签
     - 特征索引
     - 类别
     - 子节点(多叉数)字典存储
2. 创建决策树DecisionTree类
   - 属性
     - 根节点root
     - 最大深度
     - 最小分裂样本数
   - 方法
     - fit
       - 输入x_train(训练集特征样本)、y_train(训练集标签样本)，输出决策树
       - 创建决策树节点函数(递归)
       - 选取当前最优属性IG最大
       - 划分数据集splitDataSet
       - 递归创建子节点children
     - predict
       - 输入x_test(测试集特征样本),输出y_predict(分类结果)  
       - 遍历决策树获得分类结果
## 💯准确率
- [x] ID3算法实现，准确率：0.6471（调参：从根节点算起最大深度5层时达到60%准确度）
- [x] Sklearn.tree.DecisionTreeClassifier(entropy)，准确率：0.7272
- [x] Sklearn.tree.DecisionTreeClassifier(gini)，准确率：0.7262
---
> ✍️ [邢福凯 (xfkcode@github)](https://github.com/xfkcode)  
> 📅 *写于 2022年9月*