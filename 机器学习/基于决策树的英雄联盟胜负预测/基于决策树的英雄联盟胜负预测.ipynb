{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务介绍\n",
    "英雄联盟（League of Legends，LoL）是一个多人在线竞技游戏，由拳头游戏（Riot Games）公司出品。在游戏中，每位玩家控制一位有独特技能的英雄，红蓝两支队伍各有五位玩家进行对战，目标是摧毁对方的基地水晶。水晶有多座防御塔保护，通常需要先摧毁一些防御塔再摧毁水晶。玩家所控制的英雄起初非常弱，需要不断击杀小兵、野怪和对方英雄来获得金币、经验。经验可以提升英雄等级和技能等级，金币可以用来购买装备提升攻击、防御等属性。对战过程中一般没有己方单位在附近的地点是没有视野的，即无法看到对面单位，双方可以通过使用守卫来监视某个地点，洞察对面走向、制定战术。\n",
    "本数据集来自[Kaggle](https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min)，包含了9879场钻一到大师段位的单双排对局，对局双方几乎是同一水平。每条数据是前10分钟的对局情况，每支队伍有19个特征，红蓝双方共38个特征。这些特征包括英雄击杀、死亡，金钱、经验、等级情况等等。一局游戏一般会持续30至40分钟，但是实际前10分钟的局面很大程度上影响了之后胜负的走向。作为最成功的电子竞技游戏之一，对局数据、选手数据的量化与研究具有重要意义，可以启发游戏将来的发展和改进。\n",
    "\n",
    "本任务是希望同学们依据注释的要求，对代码中空缺部分进行填写，**完成决策树模型的详细实现**，根据已有的对局前10分钟特征信息，预测最后获胜方是蓝色方还是红色方，了解执行一个**机器学习任务的大致流程**，并**提交代码和实验报告**。第一次作业也是一个机器学习小实验的例子，之后的作业可能不再提供预处理等流程代码，由同学们自己设计实验完成代码编写。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入工具包\n",
    "pandas是数据分析和处理常用的工具包，非常适合处理行列表格数据。numpy是数学运算工具包，支持高效的矩阵、向量运算。sklearn是机器学习常用工具包，包括了一些已经实现好的简单模型和一些常用数据处理方法、评价指标等函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd # 数据处理\n",
    "import numpy as np # 数学运算\n",
    "from sklearn.model_selection import train_test_split, cross_validate # 划分数据集函数\n",
    "from sklearn.metrics import accuracy_score # 准确率函数\n",
    "RANDOM_SEED = 2020 # 固定随机种子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入数据\n",
    "假设数据文件放在`./data/`目录下，标准的csv文件可以用pandas里的`read_csv()`函数直接读入。文件共有40列，38个特征（红蓝方各19），1个标签列（blueWins），和一个对局标号（gameId）。对局标号不是标签也不是特征，可以舍去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = './data/high_diamond_ranked_10min.csv' # 数据路径\n",
    "data_df = pd.read_csv(csv_data, sep=',') # 读入csv文件为pandas的DataFrame\n",
    "data_df = data_df.drop(columns='gameId') # 舍去对局标号列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据概览\n",
    "对于一个机器学习问题，在拿到任务和数据后，首先需要观察数据的情况，比如我们可以通过`.iloc[0]`取出数据的第一行并输出。不难看出每个特征都存成了float64浮点数，该对局蓝色方开局10分钟有小优势。同时也可以发现有些特征列是重复冗余的，比如blueGoldDiff表示蓝色队金币优势，redGoldDiff表示红色方金币优势，这两个特征是完全对称的互为相反数。blueCSPerMin是蓝色方每分钟击杀小兵数，它乘10就是10分钟所有小兵击杀数blueTotalMinionsKilled。在之后的特征处理过程中可以考虑去除这些冗余特征。\n",
    "另外，pandas有非常方便的`describe()`函数，可以直接通过DataFrame进行调用，可以展示每一列数据的一些统计信息，对数据分布情况有大致了解，比如blueKills蓝色方击杀英雄数在前十分钟的平均数是6.14、方差为2.93，中位数是6，百分之五十以上的对局中该特征在4-8之间，等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blueWins                            0.0\n",
      "blueWardsPlaced                    28.0\n",
      "blueWardsDestroyed                  2.0\n",
      "blueFirstBlood                      1.0\n",
      "blueKills                           9.0\n",
      "blueDeaths                          6.0\n",
      "blueAssists                        11.0\n",
      "blueEliteMonsters                   0.0\n",
      "blueDragons                         0.0\n",
      "blueHeralds                         0.0\n",
      "blueTowersDestroyed                 0.0\n",
      "blueTotalGold                   17210.0\n",
      "blueAvgLevel                        6.6\n",
      "blueTotalExperience             17039.0\n",
      "blueTotalMinionsKilled            195.0\n",
      "blueTotalJungleMinionsKilled       36.0\n",
      "blueGoldDiff                      643.0\n",
      "blueExperienceDiff                 -8.0\n",
      "blueCSPerMin                       19.5\n",
      "blueGoldPerMin                   1721.0\n",
      "redWardsPlaced                     15.0\n",
      "redWardsDestroyed                   6.0\n",
      "redFirstBlood                       0.0\n",
      "redKills                            6.0\n",
      "redDeaths                           9.0\n",
      "redAssists                          8.0\n",
      "redEliteMonsters                    0.0\n",
      "redDragons                          0.0\n",
      "redHeralds                          0.0\n",
      "redTowersDestroyed                  0.0\n",
      "redTotalGold                    16567.0\n",
      "redAvgLevel                         6.8\n",
      "redTotalExperience              17047.0\n",
      "redTotalMinionsKilled             197.0\n",
      "redTotalJungleMinionsKilled        55.0\n",
      "redGoldDiff                      -643.0\n",
      "redExperienceDiff                   8.0\n",
      "redCSPerMin                        19.7\n",
      "redGoldPerMin                    1656.7\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blueWins</th>\n",
       "      <th>blueWardsPlaced</th>\n",
       "      <th>blueWardsDestroyed</th>\n",
       "      <th>blueFirstBlood</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueAssists</th>\n",
       "      <th>blueEliteMonsters</th>\n",
       "      <th>blueDragons</th>\n",
       "      <th>blueHeralds</th>\n",
       "      <th>...</th>\n",
       "      <th>redTowersDestroyed</th>\n",
       "      <th>redTotalGold</th>\n",
       "      <th>redAvgLevel</th>\n",
       "      <th>redTotalExperience</th>\n",
       "      <th>redTotalMinionsKilled</th>\n",
       "      <th>redTotalJungleMinionsKilled</th>\n",
       "      <th>redGoldDiff</th>\n",
       "      <th>redExperienceDiff</th>\n",
       "      <th>redCSPerMin</th>\n",
       "      <th>redGoldPerMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "      <td>9879.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499038</td>\n",
       "      <td>22.288288</td>\n",
       "      <td>2.824881</td>\n",
       "      <td>0.504808</td>\n",
       "      <td>6.183925</td>\n",
       "      <td>6.137666</td>\n",
       "      <td>6.645106</td>\n",
       "      <td>0.549954</td>\n",
       "      <td>0.361980</td>\n",
       "      <td>0.187974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>16489.041401</td>\n",
       "      <td>6.925316</td>\n",
       "      <td>17961.730438</td>\n",
       "      <td>217.349226</td>\n",
       "      <td>51.313088</td>\n",
       "      <td>-14.414111</td>\n",
       "      <td>33.620306</td>\n",
       "      <td>21.734923</td>\n",
       "      <td>1648.904140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500024</td>\n",
       "      <td>18.019177</td>\n",
       "      <td>2.174998</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>3.011028</td>\n",
       "      <td>2.933818</td>\n",
       "      <td>4.064520</td>\n",
       "      <td>0.625527</td>\n",
       "      <td>0.480597</td>\n",
       "      <td>0.390712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216900</td>\n",
       "      <td>1490.888406</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>1198.583912</td>\n",
       "      <td>21.911668</td>\n",
       "      <td>10.027885</td>\n",
       "      <td>2453.349179</td>\n",
       "      <td>1920.370438</td>\n",
       "      <td>2.191167</td>\n",
       "      <td>149.088841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11212.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>10465.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-11467.000000</td>\n",
       "      <td>-8348.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>1121.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15427.500000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>17209.500000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>-1596.000000</td>\n",
       "      <td>-1212.000000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>1542.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16378.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17974.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>1637.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17418.500000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>18764.500000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1585.500000</td>\n",
       "      <td>1290.500000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>1741.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22732.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>22269.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10830.000000</td>\n",
       "      <td>9333.000000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>2273.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          blueWins  blueWardsPlaced  blueWardsDestroyed  blueFirstBlood  \\\n",
       "count  9879.000000      9879.000000         9879.000000     9879.000000   \n",
       "mean      0.499038        22.288288            2.824881        0.504808   \n",
       "std       0.500024        18.019177            2.174998        0.500002   \n",
       "min       0.000000         5.000000            0.000000        0.000000   \n",
       "25%       0.000000        14.000000            1.000000        0.000000   \n",
       "50%       0.000000        16.000000            3.000000        1.000000   \n",
       "75%       1.000000        20.000000            4.000000        1.000000   \n",
       "max       1.000000       250.000000           27.000000        1.000000   \n",
       "\n",
       "         blueKills   blueDeaths  blueAssists  blueEliteMonsters  blueDragons  \\\n",
       "count  9879.000000  9879.000000  9879.000000        9879.000000  9879.000000   \n",
       "mean      6.183925     6.137666     6.645106           0.549954     0.361980   \n",
       "std       3.011028     2.933818     4.064520           0.625527     0.480597   \n",
       "min       0.000000     0.000000     0.000000           0.000000     0.000000   \n",
       "25%       4.000000     4.000000     4.000000           0.000000     0.000000   \n",
       "50%       6.000000     6.000000     6.000000           0.000000     0.000000   \n",
       "75%       8.000000     8.000000     9.000000           1.000000     1.000000   \n",
       "max      22.000000    22.000000    29.000000           2.000000     1.000000   \n",
       "\n",
       "       blueHeralds  ...  redTowersDestroyed  redTotalGold  redAvgLevel  \\\n",
       "count  9879.000000  ...         9879.000000   9879.000000  9879.000000   \n",
       "mean      0.187974  ...            0.043021  16489.041401     6.925316   \n",
       "std       0.390712  ...            0.216900   1490.888406     0.305311   \n",
       "min       0.000000  ...            0.000000  11212.000000     4.800000   \n",
       "25%       0.000000  ...            0.000000  15427.500000     6.800000   \n",
       "50%       0.000000  ...            0.000000  16378.000000     7.000000   \n",
       "75%       0.000000  ...            0.000000  17418.500000     7.200000   \n",
       "max       1.000000  ...            2.000000  22732.000000     8.200000   \n",
       "\n",
       "       redTotalExperience  redTotalMinionsKilled  redTotalJungleMinionsKilled  \\\n",
       "count         9879.000000            9879.000000                  9879.000000   \n",
       "mean         17961.730438             217.349226                    51.313088   \n",
       "std           1198.583912              21.911668                    10.027885   \n",
       "min          10465.000000             107.000000                     4.000000   \n",
       "25%          17209.500000             203.000000                    44.000000   \n",
       "50%          17974.000000             218.000000                    51.000000   \n",
       "75%          18764.500000             233.000000                    57.000000   \n",
       "max          22269.000000             289.000000                    92.000000   \n",
       "\n",
       "        redGoldDiff  redExperienceDiff  redCSPerMin  redGoldPerMin  \n",
       "count   9879.000000        9879.000000  9879.000000    9879.000000  \n",
       "mean     -14.414111          33.620306    21.734923    1648.904140  \n",
       "std     2453.349179        1920.370438     2.191167     149.088841  \n",
       "min   -11467.000000       -8348.000000    10.700000    1121.200000  \n",
       "25%    -1596.000000       -1212.000000    20.300000    1542.750000  \n",
       "50%      -14.000000          28.000000    21.800000    1637.800000  \n",
       "75%     1585.500000        1290.500000    23.300000    1741.850000  \n",
       "max    10830.000000        9333.000000    28.900000    2273.200000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_df.iloc[0]) # 输出第一行数据\n",
    "data_df.describe() # 每列特征的简单统计信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增删特征\n",
    "传统的机器学习模型大部分都是基于特征的，因此特征工程是机器学习中非常重要的一步。有时构造一个好的特征比改进一个模型带来的提升更大。这里简单展示一些特征处理的例子。首先，上面提到，特征列中有些特征信息是完全冗余的，会给模型带来不必要的计算量，可以去除。其次，相比于红蓝双方击杀、助攻的绝对值，可能双方击杀英雄的差值更能体现出当前对战的局势。因此，我们可以构造红蓝双方对应特征的差值。数据文件中已有的差值是金币差GoldDiff和经验差ExperienceDiff，实际上每个对应特征都可以构造这样的差值特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = ['blueGoldDiff', 'redGoldDiff', \n",
    "                 'blueExperienceDiff', 'redExperienceDiff', \n",
    "                 'blueCSPerMin', 'redCSPerMin', \n",
    "                 'blueGoldPerMin', 'redGoldPerMin'] # 需要舍去的特征列\n",
    "df = data_df.drop(columns=drop_features) # 舍去特征列\n",
    "info_names = [c[3:] for c in df.columns if c.startswith('red')] # 取出要作差值的特征名字（除去red前缀）\n",
    "for info in info_names: # 对于每个特征名字\n",
    "    df['br' + info] = df['blue' + info] - df['red' + info] # 构造一个新的特征，由蓝色特征减去红色特征，前缀为br\n",
    "# 其中FirstBlood为首次击杀最多有一只队伍能获得，brFirstBlood=1为蓝，0为没有产生，-1为红\n",
    "df = df.drop(columns=['blueFirstBlood', 'redFirstBlood']) # 原有的FirstBlood可删除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征离散化\n",
    "决策树ID3算法一般是基于离散特征的，本例中存在很多连续的数值特征，例如队伍金币。直接应用该算法每个值当作一个该特征的一个取值可能造成严重的过拟合，因此需要对特征进行离散化，即将一定范围内的值映射成一个值，例如对用户年龄特征，将0-10映射到0，11-18映射到1，19-25映射到2，25-30映射到3，等等类似，然后在决策树构建时使用映射后的值计算信息增益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_df = df.copy() # 先复制一份数据\n",
    "for c in df.columns[1:]: # 遍历每一列特征，跳过标签列\n",
    "    if len(np.unique(df[c]))>10:\n",
    "        discrete_df[c] = pd.qcut(df[c],([0.,0.2,0.4,0.6,0.8,1.]),labels=[0,1,2,3,4])\n",
    "        continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集准备\n",
    "构建机器学习模型前要构建训练和测试的数据集。在本例中首先需要分开标签和特征，标签是不能作为模型的输入特征的，就好比作业和试卷答案不能在做题和考试前就告诉学生。测试一个模型在一个任务上的效果至少需要训练集和测试集，训练集用来训练模型的参数，好比学生做作业获得知识，测试集用来测试模型效果，好比期末考试考察学生学习情况。测试集的样本不应该出现在训练集中，否则会造成模型效果估计偏高，好比考试时出的题如果是作业题中出现过的，会造成考试分数不能准确衡量学生的学习情况，估计值偏高。划分训练集和测试集有多种方法，下面首先介绍的是随机取一部分如20%作测试集，剩下作训练集。sklearn提供了相关工具函数`train_test_split`。sklearn的输入输出一般为numpy的array矩阵，需要先将pandas的DataFrame取出为numpy的array矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9879,), (9879, 43), (7903, 43), (1976, 43), (7903,), (1976,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_y = discrete_df['blueWins'].values # 所有标签数据\n",
    "feature_names = discrete_df.columns[1:] # 所有特征的名称\n",
    "all_x = discrete_df[feature_names].values # 所有原始特征值，pandas的DataFrame.values取出为numpy的array矩阵\n",
    "\n",
    "# 划分训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_x, all_y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "all_y.shape, all_x.shape, x_train.shape, x_test.shape, y_train.shape, y_test.shape # 输出数据行列信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树模型的实现\n",
    "- 根据训练数据构建一颗决策树\n",
    "- 决策树会逐渐把训练集合分成越来越小的子集\n",
    "- 当子集纯净后不再分裂\n",
    "- 或者接受一个不完美的决策\n",
    "\n",
    "### ID3\n",
    "- 自顶向下，贪心算法\n",
    "- 递归算法\n",
    "- 核心循环：\n",
    "  - $A$：下一步 **最佳** 决策属性\n",
    "  \n",
    "      Impurity(混杂度)\n",
    "      \n",
    "      IG(信息增益)\n",
    "\n",
    "  - 将 $A$ 作为当前节点决策属性\n",
    "  - 对 $A(vi)$ 的每个值，创建与其对应的新的子节点\n",
    "  - 根据属性值将训练样本分配到各个节点\n",
    "  - 如果 **训练样本被完美分类** ，则退出循环，否则继续下探分裂新的叶节点\n",
    "  \n",
    "      相同的输出类别 或 相同的输入类别\n",
    "\n",
    "##### 构建决策树\n",
    "1. 创建节点Node类\n",
    "   - 属性\n",
    "     - 数据子集x特征，y标签\n",
    "     - 特征索引\n",
    "     - 类别\n",
    "     - 子节点(多叉数)字典存储\n",
    "2. 创建决策树DecisionTree类\n",
    "   - 属性\n",
    "     - 根节点root\n",
    "     - 最大深度\n",
    "     - 最小分裂样本数\n",
    "   - 方法\n",
    "     - fit\n",
    "       - 输入x_train(训练集特征样本)、y_train(训练集标签样本)，输出决策树\n",
    "       - 创建决策树节点函数(递归)\n",
    "       - 选取当前最优属性IG最大\n",
    "       - 划分数据集splitDataSet\n",
    "       - 递归创建子节点children\n",
    "     - predict\n",
    "       - 输入x_test(测试集特征样本),输出y_predict(分类结果)  \n",
    "       - 遍历决策树获得分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集：特征x(7903,43),标签y(7903,)\n",
    "class Node:\n",
    "    def __init__(self, x, y, cla, feature_index=None, children={}):\n",
    "        self.x_data = x # 特征数据集 \n",
    "        self.y_label = y # 标签数据集\n",
    "        self.ftidx = feature_index # 特征索引，非叶节点特征(属性)，叶节点None\n",
    "        self.cla = cla # 类别，叶节点[0,1],非叶节点None\n",
    "        self.children=children #子节点字典存储\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, classes, features, \n",
    "                 max_depth=10, min_samples_split=10): \n",
    "        self.classes = classes # classes表示模型分类总共有几类\n",
    "        self.features = features # features是每个特征的名字，也方便查询总的共特征数\n",
    "        self.max_depth = max_depth # 最大深度\n",
    "        self.min_samples_split = min_samples_split # 最小样本数\n",
    "        self.root = None # 定义根节点，未训练时为空\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        assert len(self.features) == len(x[0])\n",
    "        '''\n",
    "        函数说明：信息熵计算函数\n",
    "        Parameters:\n",
    "            y - 标签数据集\n",
    "        Returns:\n",
    "            Ent - 信息熵\n",
    "        '''\n",
    "        def Entropy(y):\n",
    "            p=0\n",
    "            Ent=0\n",
    "            C=Counter(y)\n",
    "            for cls,freq in C.items():\n",
    "                p=freq/len(y)\n",
    "                Ent-=p*np.log2(p)\n",
    "            return Ent\n",
    "\n",
    "\n",
    "        '''\n",
    "        函数说明：按照给定特征划分数据集\n",
    "        Parameters:\n",
    "            x - 数据集features\n",
    "            y - 数据集labels\n",
    "            feature_index - 特征索引\n",
    "        Return:\n",
    "            retx - 数据集feature划分字典(按照给定特征分类)\n",
    "            rety - 数据集label划分字典(按照给定特征分类)\n",
    "        '''\n",
    "        def splitDataSet(x,y,feature_index):\n",
    "            retx={}\n",
    "            rety={}\n",
    "            feature=x[:,feature_index]\n",
    "            # cls给定特征类别\n",
    "            cls=pd.Series(feature).unique()\n",
    "            for i in cls:\n",
    "                tempx=[]\n",
    "                tempy=[]\n",
    "                for j in range(len(x)):\n",
    "                    if feature[j] == i:\n",
    "                        tempx.append(x[j])\n",
    "                        tempy.append(y[j])\n",
    "                retx[i]=np.array(tempx)\n",
    "                rety[i]=np.array(tempy)\n",
    "            return retx,rety        \n",
    "            \n",
    "                \n",
    "        '''\n",
    "        函数说明：选择最优特征\n",
    "        Parameters:\n",
    "            x - 数据集features\n",
    "            y - 数据集labels\n",
    "            feature_order - 特征序列\n",
    "        Returns:\n",
    "            bestfeature - 最佳分裂特征(索引)\n",
    "        '''\n",
    "        def Bestfeature(x,y,feature_order):\n",
    "            baseEntropy=Entropy(y)\n",
    "            bestIG=0.0\n",
    "            bestfeature=-1\n",
    "            for i in range(len(self.features)):\n",
    "                if i in feature_order:\n",
    "                    continue\n",
    "                spdatax,spdatay=splitDataSet(x,y,i)\n",
    "                newEntropy=0.0\n",
    "                for cls,lable in spdatay.items():\n",
    "                    p=len(lable)/len(x)\n",
    "                    newEntropy+=p*Entropy(lable)\n",
    "                infoIG=baseEntropy-newEntropy\n",
    "                if infoIG > bestIG:\n",
    "                    bestIG=infoIG\n",
    "                    bestfeature=i\n",
    "            return bestfeature    \n",
    "                \n",
    "\n",
    "        '''\n",
    "        函数说明：创建决策树(递归创建节点)\n",
    "        Parameters:\n",
    "            x - 数据集features\n",
    "            y - 数据集labels\n",
    "            infodepth - 当前节点深度\n",
    "            max_depth - 最大深度\n",
    "            min_sample - 最小分裂样本数\n",
    "        Returns:\n",
    "            node - 节点\n",
    "        '''\n",
    "        def CreateTree(x, y,infodepth,feature_order, max_depth, min_sample):\n",
    "            if len(Counter(y)) == 1:\n",
    "                return Node(x,y,y[0])\n",
    "            if infodepth > max_depth:\n",
    "                classes = list(Counter(y).keys())[0] if Counter(y)[0] > Counter(y)[1] else list(Counter(y).keys())[1]\n",
    "                return Node(x,y,classes)\n",
    "            if len(y) < min_sample:\n",
    "                classes = list(Counter(y).keys())[0] if Counter(y)[0] > Counter(y)[1] else list(Counter(y).keys())[1]\n",
    "                return Node(x,y,classes)\n",
    "            \n",
    "            bestf=Bestfeature(x,y,feature_order)\n",
    "            if bestf == -1:\n",
    "                classes = list(Counter(y).keys())[0] if Counter(y)[0] > Counter(y)[1] else list(Counter(y).keys())[1]\n",
    "                return Node(x,y,classes,None)\n",
    "            feature_order.append(bestf)\n",
    "            spdatax,spdatay=splitDataSet(x,y,bestf)\n",
    "            children={}\n",
    "            for i in range(len(spdatax)):\n",
    "                cls=list(spdatax.keys())[i]\n",
    "                subx=list(spdatax.values())[i]\n",
    "                suby=list(spdatay.values())[i]\n",
    "                childnode=CreateTree(subx,suby,infodepth+1,feature_order,\n",
    "                                     max_depth,min_sample)\n",
    "                children[cls]=childnode\n",
    "            node=Node(x,y,None,bestf,children=children)\n",
    "            return node\n",
    "            \n",
    "\n",
    "        init_depth=0\n",
    "        init_feature_od=[]\n",
    "        self.root=CreateTree(x,y,init_depth,init_feature_od,self.max_depth,self.min_samples_split)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self,x):\n",
    "        assert len(x.shape) == 1 or len(x.shape) == 2 \n",
    "        '''\n",
    "        函数说明:分类预测，递归遍历决策树从根节点到叶子节点\n",
    "        Parameters:\n",
    "            data - 一个测试样本特征数据\n",
    "            node - 决策树根节点\n",
    "        Returns:\n",
    "            class_result - 分类结果\n",
    "        '''\n",
    "        def classifier(data,node):\n",
    "            class_result=0\n",
    "            if node.cla == None:\n",
    "                nextnode=node.children[data[node.ftidx]]\n",
    "                class_result=classifier(data,nextnode)\n",
    "            else:\n",
    "                class_result=node.cla\n",
    "            return class_result\n",
    "        \n",
    "        \n",
    "        y_predict=[]\n",
    "        for eachrow in x:\n",
    "            yp=classifier(eachrow,self.root)\n",
    "            y_predict.append(yp)\n",
    "        return np.array(y_predict)\n",
    "        \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "accuracy: 0.6471\n"
     ]
    }
   ],
   "source": [
    "# 定义决策树模型，传入算法参数\n",
    "DT = DecisionTree(classes=[0,1], features=feature_names, max_depth=4, min_samples_split=10) # 最大深度从0算起，5层\n",
    "DT.fit(x_train, y_train) # 在训练集上训练\n",
    "p_test = DT.predict(x_train) # 在测试集上预测，获得预测值\n",
    "print(p_test) # 输出预测值\n",
    "test_acc = accuracy_score(p_test, y_train) # 将测试预测值与测试集标签对比获得准确率\n",
    "print('accuracy: {:.4f}'.format(test_acc)) # 输出准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 1 1]\n",
      "accuracy: 0.7272\n"
     ]
    }
   ],
   "source": [
    "# sklearn决策树实现(entropy)\n",
    "from sklearn import tree\n",
    "DT = tree.DecisionTreeClassifier(criterion='entropy',max_depth=5,min_samples_split=10)\n",
    "DT.fit(x_train, y_train) \n",
    "\n",
    "p_test = DT.predict(x_test) \n",
    "print(p_test) \n",
    "test_acc = accuracy_score(p_test, y_test) \n",
    "print('accuracy: {:.4f}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 1 1]\n",
      "accuracy: 0.7257\n"
     ]
    }
   ],
   "source": [
    "# sklearn决策树实现(gini)\n",
    "from sklearn import tree\n",
    "DT = tree.DecisionTreeClassifier(criterion='gini',max_depth=5,min_samples_split=10)\n",
    "DT.fit(x_train, y_train) \n",
    "\n",
    "p_test = DT.predict(x_test) \n",
    "print(p_test) \n",
    "test_acc = accuracy_score(p_test, y_test) \n",
    "print('accuracy: {:.4f}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a825f8e8905b8e64233e6384cfa1616d0baa442a3b458fa78e4916d5c671b0d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
