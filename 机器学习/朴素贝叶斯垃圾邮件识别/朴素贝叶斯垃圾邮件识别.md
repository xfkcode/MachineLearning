# 朴素贝叶斯垃圾邮件识别⭐
## 🧠朴素贝叶斯
- 假设目标函数 $f:X\rightarrow V$, 其中每个样本 $x=(a_1,a_2,...,a_n)$  
  那么最有可能的 $f(X)$ 的值是：  
$$v_{MAP}=\underset{v_j\in V}{\mathrm{argmax}} P(x|v_j)P(v_j)$$
- 朴素贝叶斯假设：  
$$P(x|v_j)=P(a_1,a_2,...,a_n|v_j)=\prod_i P(a_i|v_j)$$
&emsp;&emsp;&emsp;🧩**拉普拉斯平滑**🧩(***Laplace Smoothing***) 又被称为加1平滑，为了解决0概率问题:  
$$P(a_i|v_j)=\frac{m_{il}+\lambda}{m_j+n\lambda}$$  
&emsp;&emsp;&emsp; 其中, $P(a_i|v_j)$ 是第 $j$ 个类别的第 $i$ 维特征的第 $l$ 个取值的条件概率。    
&emsp;&emsp;&emsp; $m_j$ 是训练集中输出为第 $j$ 类的样本个数。 $\lambda$ 为一个大于0的常数，常常取值为1，即拉普拉斯平滑，也可以取其他值。
- 朴素贝叶斯分类器：  
 $$📌v_{NB}=\underset{v_j\in V}{\mathrm{argmax}}  \{\log{P(v_j)}+\sum_i \log{P(a_i|v_j)}\}📌$$   
&emsp;&emsp;&emsp;❗❗❗取对数可以防止下溢出❗❗❗
## 📬邮件正文文本特征以及标签提取
- **全部数据集**："./trec06c-utf8/data/"📂路径下 ***64620*** 条邮件📧
- **小规模数据集**："./trec06c-utf8/data/000/"📂路径下 ***300*** 条邮件📧
## ✂️数据划分
- 训练集 : 测试集（***8:2***）
```python
# 自主实现数据集划分 (random模块)
import random
data_class_list = list(zip(data_list, label_list)) 
random.shuffle(data_class_list)
index = int(len(data_class_list) * 0.2) + 1
train_list = data_class_list[index:]
test_list = data_class_list[:index]
train_data_list, train_class_list = zip(*train_list)
test_data_list, test_class_list = zip(*test_list)
```
📢注：随机划分，每次运行结果不同
```python
# sklearn实现 (sklearn.model_selection.train_test_split)
from sklearn.model_selection import train_test_split
train_data_list, test_data_list, train_class_list, test_class_list = \
train_test_split(data_list,label_list, test_size=0.2,random_state=250)
```
📢注：固定种子 ***250*** ，每次运行结果相同
## 📋特征选择（词表构建）
1. 将所有文本特征汇总计数（建立字典）并按照出现频数从大到小排序
2. 去除一些对分类没有太大关联的词汇，例如：'你'、'我'、'的'等等（建立了一个word.text文件）
3.  确定特征数量，构建特征词表
## ♻️模型构建
### 🧰***sklearn*** 实现，***MultinomialNB*** ：先验为多项式分布的朴素贝叶斯
```python
class sklearn.naive_bayes.MultinomialNB(alpha=1.0,fit_prior,class_prior=None)
```
### ♟️扩展：**自主** 实现, **二分类朴素贝叶斯模型**
```python
# 二分类朴素贝叶斯模型
class NB:
    def __init__(self) -> None:
        self.p0Vect=[]
        self.p1Vect=[]
        self.pAbusive=0.5
        
    '''
    函数说明：训练
    Parameters:
        x - 训练集features
        y - 训练集labels
    Returns:
        self.p0Vect - P(w0|0),P(w1|0),P(w2|0)···
        self.p1Vect - P(w0|1),P(w1|1),P(w2|1)···
        self.pAbusive - 先验概率
    '''
    def fit(self,x,y):
        numsample=len(x)
        numfeature=len(x[0])
        self.pAbusive = sum(y)/float(numsample)
        p0Num = np.ones(numfeature); p1Num = np.ones(numfeature)
        # 分母初始化为2,拉普拉斯平滑
        p0Denom = 2.0; p1Denom = 2.0
        for i in range(numsample):
            if y[i] == 1:
                p1Num += x[i]
                p1Denom += sum(x[i])
            else:
                p0Num += x[i]
                p0Denom += sum(x[i])
        # 取对数，防止下溢出
        self.p1Vect = np.log(p1Num/p1Denom)
        self.p0Vect = np.log(p0Num/p0Denom)
        return self.p0Vect,self.p1Vect,self.pAbusive
    
    '''
    函数说明：预测
    Parameters:
        x_test - 测试集features
    Returns:
        yp - 回归预测结果
    ''' 
    def predict(self,x_test):
        py=[]
        for x in x_test:
            p1 = sum(x * self.p1Vect) + np.log(self.pAbusive)
            p0 = sum(x * self.p0Vect) + np.log(1.0 - self.pAbusive)
            if p1 > p0:
                py.append(1)
            else:
                py.append(0)
        return py
```

## 📈对比特征数目（词表大小）对模型效果的影响
测试特征数目从500到1500对模型效果的影响：

- 📐分别画出了feature_num对以下指标的影响趋势  
  准确率 ***Accuracy***：准确率随着特征数目的增大而增大  
  
  精准率 ***Precision***：精确率随着特征数目的增大而增大然后趋于平稳伴随着一些抖动  
    
  召回率 ***Recall***：召回率随着特征数目的增大而增大（准确率变化相似）  
    
## 💯模型分类结果分析
- 选取 ***2500*** 个特征构建词表训练模型  
  - [x] 准确率 ***Accuracy***
  - [x] 精准率 ***Precision***
  - [x] 召回率 ***Recall***
  
&emsp;👏👏👏 **指标均超过：** ***90%*** 👏👏👏
```python
# sklearn模型，MultinomialNB
sklearn模型准确率: 0.9484679665738162
sklearn模型精确率: 0.972106824925816
sklearn模型召回率: 0.9500057997912075
# 自主实现模型，NB
自主实现模型准确率: 0.9484679665738162
自主实现模型精确率: 0.972106824925816
自主实现模型召回率: 0.9500057997912075
```
---
> ✍️ [邢福凯 (xfkcode@github)](https://github.com/xfkcode)  
> 📅 *写于 2022年10月*