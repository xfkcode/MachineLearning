# Final ProjectÔºöÊüêÈóØÂÖ≥Á±ªÊâãÊ∏∏Áî®Êà∑ÊµÅÂ§±È¢ÑÊµã‚≠ê

**ÊüêÈóØÂÖ≥Á±ªÊâãÊ∏∏Áî®Êà∑ÊµÅÂ§±È¢ÑÊµã**   
***user_id*** Áî®Êà∑ID üëΩ ***num_attempts*** Â∞ùËØïÊ¨°Êï∞ ‚è≥ ***clear_rate*** ÈÄöÂÖ≥Áéá üé±   
***avg_duration*** Âπ≥ÂùáÁî®Êó∂ ‚è±Ô∏è ***avg_reststep*** Âπ≥ÂùáÂâ©‰ΩôÊ≠•Êï∞ÊØî üë£   
***cum_help*** Á¥ØÁßØÂ∏ÆÂä©Ê¨°Êï∞ ‚úã ***landing_days*** ÁôªÈôÜÂ§©Êï∞ üìÖ ***label*** ÊµÅÂ§± ‚úîÔ∏è‚ùå

## **ü•Ω**Êï∞ÊçÆÊ¶ÇËßà

Êú¨Ê¨°Êï∞ÊçÆÂíå‰ª•ÂæÄÁªìÊûÑÂåñÁöÑÂΩ¢Âºè‰∏çÂêåÔºåÂ±ïÁé∞ÁöÑÊòØÊõ¥ÂéüÂßãÁöÑÊï∞ÊçÆËÆ∞ÂΩïÔºåÊõ¥Êé•ËøëÂÖ¨Âè∏ÂÆûÈôÖÊó•ÂøóÁöÑÂΩ¢Âºè  
ÂÖ±ÂåÖÂê´ ***5*** ‰∏™Êñá‰ª∂Ôºö  
üóÉÔ∏è **level_seq.csv** üìÆ **level_meta.csv**   
üöä **train.csv** ‚≠ï **dev.csv** üß™ **test.csv**  

#### üî∞ÂØºÂÖ•Êï∞ÊçÆ
- **ËÆ≠ÁªÉÈõÜ**Ôºö"./data/" üìÇË∑ØÂæÑ‰∏ã *train.csv* üìùÊñá‰ª∂
  ÂåÖÂê´ÊÄªÂÖ± **8158** Êù°Êï∞ÊçÆÊ†∑Êú¨ üíæ
  ÊØèÊù°Ê†∑Êú¨ÂåÖÂê´ **user_id/label**
- **È™åËØÅÈõÜ**Ôºö"./data/" üìÇË∑ØÂæÑ‰∏ã *dev.csv* üìùÊñá‰ª∂
  ÂåÖÂê´ÊÄªÂÖ± **2658** Êù°Êï∞ÊçÆÊ†∑Êú¨ üíæ
  ÊØèÊù°Ê†∑Êú¨ÂåÖÂê´ **user_id/label** 
  [üîß]ÔºöÂèØËøõË°åË∂ÖÂèÇÊï∞ÁöÑÁöÑË∞ÉÊï¥Ôºõ‰πüÂèØ‰Ωú‰∏∫Á¶ªÁ∫øÊµãËØïÈõÜÔºåËøõË°åÊµãËØï
- **ÊµãËØïÈõÜ**Ôºö"./data/" üìÇË∑ØÂæÑ‰∏ã *test.csv* üìùÊñá‰ª∂
  ÂåÖÂê´ÊÄªÂÖ± **2773** Êù°Êï∞ÊçÆÊ†∑Êú¨ üíæ
  ÊØèÊù°Ê†∑Êú¨‰ªÖÂåÖÂê´ **user_id** 
  [‚òÅÔ∏è]ÔºöÊµãËØïÈõÜÁúüÂÆûÊ†áÁ≠æÂú®‰∫ëÁ´ØÔºåÂèØ‰∏ä‰º†ÁªìÊûúËØÑ‰º∞ÊÄßËÉΩ

[***dataDownload*** **ÈìæÊé•**]()üëà
[üì¢]ÔºöÊâÄÊúâÊñá‰ª∂ *user_id* Áªü‰∏Ä„ÄÇ
‚úîÔ∏è‚öôÔ∏èÂÄüÂä© **pandas** ËØªÂÖ•Ê†áÂáÜ *csv* Ê†ºÂºèÊñá‰ª∂ÁöÑÂáΩÊï∞ `read_csv()` Â∞ÜÊï∞ÊçÆËΩ¨Êç¢‰∏∫ `DataFrame` ÁöÑÂΩ¢Âºè„ÄÇ

```python
# ËØªÂÖ•csvÊñá‰ª∂‰∏∫pandasÁöÑDataFrame
seq_df = pd.read_csv('./data/level_seq.csv', sep='\t')
meta_df = pd.read_csv('./data/level_meta.csv', sep='\t')
train_df = pd.read_csv('./data/train.csv', sep='\t')
dev_df = pd.read_csv('./data/dev.csv', sep='\t')
test_df = pd.read_csv('./data/test.csv', sep='\t')
```

## **üß†**ÁâπÂæÅÂ∑•Á®ã

Ê†πÊçÆ **level_seq.csv** ÈíàÂØπ **Áî®Êà∑** ÊèêÂèñÁâπÂæÅ

#### üóÉÔ∏èlevel_seq.csv
üíöÊ†∏ÂøÉÊï∞ÊçÆÊñá‰ª∂üíö 
ÂåÖÂê´Áî®Êà∑Ê∏∏Áé©ÊØè‰∏™ÂÖ≥Âç°ÁöÑËÆ∞ÂΩïÔºåÊØè‰∏ÄÊù°ËÆ∞ÂΩïÊòØÂØπÊüê‰∏™ÂÖ≥Âç°ÁöÑ‰∏ÄÊ¨°Â∞ùËØïÔºåÂÖ∑‰ΩìÊØèÂàóÁöÑÂê´‰πâÂ¶Ç‰∏ãÔºö

- `user_id`ÔºöÁî®Êà∑ idÔºåÂíåËÆ≠ÁªÉ„ÄÅÈ™åËØÅ„ÄÅÊµãËØïÈõÜ‰∏≠ÁöÑÂèØ‰ª•ÂåπÈÖçÔºõ

* `level_id`ÔºöÂÖ≥Âç° id
* `f_success`ÔºöÊòØÂê¶ÈÄöÂÖ≥Ôºà1ÔºöÈÄöÂÖ≥Ôºå0ÔºöÂ§±Ë¥•Ôºâ
* `f_duration`ÔºöÊ≠§Ê¨°Â∞ùËØïÊâÄÁî®ÁöÑÊó∂Èó¥ÔºàÂçï‰Ωç sÔºâ
* `f_reststep`ÔºöÂâ©‰ΩôÊ≠•Êï∞‰∏éÈôêÂÆöÊ≠•Êï∞‰πãÊØîÔºàÂ§±Ë¥•‰∏∫ 0Ôºâ
* `f_help`ÔºöÊòØÂê¶‰ΩøÁî®‰∫ÜÈÅìÂÖ∑„ÄÅÊèêÁ§∫Á≠âÈ¢ùÂ§ñÂ∏ÆÂä©Ôºà1Ôºö‰ΩøÁî®Ôºå0ÔºöÊú™‰ΩøÁî®Ôºâ
* `time`ÔºöÊó∂Èó¥Êà≥

#### ‚ôüÔ∏èÁâπÂæÅ Features

|      | user_id | Â∞ùËØïÊ∏∏ÊàèÊ¨°Êï∞ |   ÈÄöÂÖ≥Áéá | Ê∏∏ÊàèÂπ≥ÂùáÁî®Êó∂ | Âπ≥ÂùáÂâ©‰ΩôÊ≠•Êï∞ÊØî | Á¥ØÁßØÂ∏ÆÂä©Ê¨°Êï∞ | ÁôªÈôÜÂ§©Êï∞ | label |
| ---: | ------: | -----------: | -------: | -----------: | -------------: | -----------: | -------: | ----: |
|    0 |    2774 |          215 | 0.632558 |        118.1 |       0.189056 |           18 |        4 |     0 |
|    1 |    2775 |          111 | 0.738739 |        169.7 |       0.258456 |           14 |        3 |     0 |
|    2 |    2776 |           69 | 0.637681 |         88.7 |       0.186543 |            1 |        3 |     1 |
|    3 |    2777 |          286 | 0.506993 |        142.7 |       0.124245 |            4 |        4 |     0 |
|    4 |    2778 |          162 | 0.672840 |        197.8 |       0.299450 |            9 |        3 |     1 |
|  ... |     ... |          ... |      ... |          ... |            ... |          ... |      ... |   ... |

```python
''' 
ÂáΩÊï∞ËØ¥ÊòéÔºöÊ†πÊçÆ t_df ÊûÑÂª∫ÁâπÂæÅ
Parameters:
    df - level_seq.csv Áî®Êà∑‰∫§‰∫íÊï∞ÊçÆ
    t_df - train.csv/dev.csv/test.csv ËÆ≠ÁªÉÈõÜ/È™åËØÅÈõÜ/ÊµãËØïÈõÜ
Returns:
    features_df - ÁâπÂæÅÊï∞ÊçÆÈõÜ(DataFrame)
'''
def Features_Construct(df,t_df):
    features = []

    for i,user in enumerate(t_df['user_id']):
        user_features = []
        user_id = user
        user_features.append(user_id)

        user_df = seq_df.query('user_id=={}'.format(user_id))
        # Áî®Êà∑Â∞ùËØïÊ∏∏ÊàèÊ¨°Êï∞
        user_features.append(user_df.shape[0])
        user_df_succ= user_df.query('f_success==1')
        # ÈÄöÂÖ≥Áéá
        success_rate = round(user_df_succ.shape[0]/user_df.shape[0],6)
        user_features.append(success_rate)
        # ÈÄöËøáÊúÄÈ´òÂÖ≥Âç°
        # num_max = np.array(user_df_succ['level_id']).max()
        # user_features.append(num_max)
        # Ê∏∏ÊàèÂπ≥ÂùáÁî®Êó∂
        duration_mean = round(np.array(user_df['f_duration']).mean(),1)
        user_features.append(duration_mean)
        # Âπ≥Âùáreststep
        reststep_mean = round(np.array(user_df['f_reststep']).mean(),6)
        user_features.append(reststep_mean)
        # Á¥ØÁßØÂ∏ÆÂä©Ê¨°Êï∞
        times_help = np.array(user_df['f_help']).sum()
        user_features.append(times_help)
        # ÁôªÈôÜÂ§©Êï∞
        time = np.array(user_df['time'])
        day = [i[9] for i in time]
        dd = Counter(day)
        days = len(dd)
        user_features.append(days)
        features.append(user_features)

    features_df = pd.DataFrame(features)
    features_df.columns =['user_id','Â∞ùËØïÊ∏∏ÊàèÊ¨°Êï∞','ÈÄöÂÖ≥Áéá','Ê∏∏ÊàèÂπ≥ÂùáÁî®Êó∂',
                          'Âπ≥ÂùáÂâ©‰ΩôÊ≠•Êï∞ÊØî','Á¥ØÁßØÂ∏ÆÂä©Ê¨°Êï∞','ÁôªÈôÜÂ§©Êï∞']
    return features_df
```

## **üì°**Êï∞ÊçÆÊûÑÂª∫

- ‚ö†Ô∏è**ÂΩí‰∏ÄÂåñÔºöMin-Max Normalization** 

$$
\frac{x_{i}-min(x_i)}{max(x_i)-min(x_i)}
$$

- ***DataFrame*** ËΩ¨Êç¢‚Üí ***Array*** 
  `np.array()` / `df.values` 

```python
train_features.shape,train_labels.shape,dev_features.shape,dev_labels.shape
>> (8158, 6), (8158,), (2658, 6), (2658,)
test_features.shape
>> (2773, 6)
```

## **üß∞**Ê®°ÂûãÊûÑÂª∫

#### 1.ÂÜ≥Á≠ñÊ†ë

***sklearn.tree.DecisionTreeClassifier*** üåµ

```python
class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, smin_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)
```

#### 2.Ë¥ùÂè∂ÊñØ

***sklearn.naive_bayes.BernoulliNB/ MultinomialNB/ ComplementNB*** üßê

```python
class sklearn.naive_bayes.BernoulliNB(*, alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)
class sklearn.naive_bayes.MultinomialNB(*, alpha=1.0, fit_prior=True, class_prior=None)
class sklearn.naive_bayes.ComplementNB(*, alpha=1.0, fit_prior=True, class_prior=None, norm=False)
```

#### 3.K-ËøëÈÇª

***sklearn.neighbors.KNeighborsClassifier*** üõµ

```python
class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', 
leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)
```

#### 4.ÊîØÊåÅÂêëÈáèÊú∫

***sklearn.svm.SVC*** üõí

```python
class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)
```

#### üé≤Tuning

***sklearn.model_selection.GridSearchCV*** üîç

```python
class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)
```

#### 5.ÈõÜÊàêÂ≠¶‰π†

Âü∫ÂàÜÁ±ªÂô®‚öæ 
ÂèÇÊï∞ÂàÜÂà´Ê†πÊçÆ **1-4** ÊúÄ‰Ω≥ **Accuracy** ÈÄâÊã©
***GridSearchCV*** 

- üåµ ***DT***Ôºö  `DecisionTreeClassifier(criterion='entropy', max_depth=2, min_samples_split=50)`
- üßê***NB***Ôºö  `BernoulliNB()`
- üõµ***KNN***Ôºö `KNeighborsClassifier(metric='chebyshev', n_neighbors=29, weights='uniform')`
- üõí***SVM***Ôºö `SVC(C=1, kernel='rbf', gamma=0.01)`

***sklearn.ensemble.BaggingClassifier*** üõçÔ∏è

```python
class sklearn.ensemble.BaggingClassifier(base_estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)
```

***sklearn.ensemble.AdaBoostClassifier*** ü•æ

```python
class sklearn.ensemble.AdaBoostClassifier(base_estimator=None, *, n_estimators=50, 
learning_rate=1.0, algorithm='SAMME.R', random_state=None)
```

## üíØÊ®°ÂûãËØÑ‰º∞ AUC(dev) 

#### üåµDT/ üßêNB/ üõµKNN/ üõíSVM (ROC)

![image-20221122094602715](G:\Github‰ªìÂ∫ì\MachineLearning\Êú∫Âô®Â≠¶‰π†\Final_ProjectÊüêÈóØÂÖ≥Á±ªÊâãÊ∏∏Áî®Êà∑ÊµÅÂ§±È¢ÑÊµã\ÊüêÈóØÂÖ≥Á±ªÊâãÊ∏∏Áî®Êà∑ÊµÅÂ§±È¢ÑÊµã.assets\image-20221122094602715.png) 

```python
D_T model: 
>> AUC = 0.7663
B_N model: 
>> AUC = 0.7047
KNN model: 
>> AUC = 0.7624
SVM model: 
>> AUC = 0.7730
```

#### ü•°Ensemble learning+ AUC ÂØπÊØî

```python
Bagging + D_T model: 
>> AUC = 0.7703
Bagging + B_N model: 
>> AUC = 0.7045
Bagging + KNN model: 
>> AUC = 0.7606
Bagging + SVM model: 
>> AUC = 0.7764
```

```python
Adaboost + D_T model: 
>> AUC = 0.7826
Adaboost + B_N model: 
>> AUC = 0.7045
Adaboost + SVM model: 
>> AUC = 0.5000
```

#### üî¨ Result ÂàÜÊûê

|                | **D_T**                                          | **N_B** | **KNN** | **SVM**                                      |
| :------------- | ------------------------------------------------ | ------- | ------- | :------------------------------------------- |
| **Baseline**   | 0.7663                                           | 0.7047  | 0.7624  | **<font color=CornflowerBlue>0.7730</font>** |
| **Bagging +**  | 0.7703 (up 0.5%)                                 | 0.7045  | 0.7606  | 0.7764 (up 0.4%)                             |
| **Adaboost +** | **<font color=DeepPink>0.7826</font>** (up 2.1%) | 0.7045  | NaN     | 0.5000                                       |

- ÂØπÊØî **Baseline** Best model:
  - **SVM(dev) = 0.7730** 

- 1Ô∏è‚É£Bagging + D_T Áõ∏ÊØî D_T ÊèêÂçá 0.5%Ôºõ2Ô∏è‚É£Adaboost + D_T Áõ∏ÊØî D_T ÊèêÂçá 2.1%Ôºõ3Ô∏è‚É£Bagging + SVM Áõ∏ÊØî SVM ÊèêÂçá 0.4%
  N_B ÊÄßËÉΩÂπ≥Âπ≥ÔºåÈõÜÊàêÂ≠¶‰π†+ Âπ∂Êó†ÊòéÊòæÊîπÂñÑ
  AdaBoost + SVM ÊÄßËÉΩÈ™§Èôç
  [üì¢]ÔºöKNN Ê≤°Êúâ `fit(X, y, sample_weight=None)` Êó†Ê≥ïÈÄÇÈÖç Adaboost
- **Best model** ü•á
  **\>\> AUC(dev) = 0.7826**  
  - [x] **Adaboost + D_T model** üëà

## ‚òÅÔ∏èÊµãËØïÈõÜ result.csv 

|          0 |        1 |        2 |        3 |        4 |       5 |        6 |       7 | **...** |
| ---------: | -------: | -------: | -------: | -------: | ------: | -------: | ------: | ------: |
|         ID |        1 |        2 |        3 |        4 |       5 |        6 |       7 | **...** |
| Prediction | 0.292253 | 0.348539 | 0.487569 | 0.359274 | 0.32392 | 0.353699 | 0.49843 | **...** |

[‚òÅÔ∏è]Ôºö**ÊâìÊ¶úÊàêÁª©**‚è´  

- **Adaboost + D_T model** 
  **\>\> AUC(test) = 0.77304** ‚ùó‚ùó‚ùó

\---

\> ‚úçÔ∏è [ÈÇ¢Á¶èÂáØ (xfkcode@github)](https://github.com/xfkcode)  

\> üìÖ **ÂÜô‰∫é 2022Âπ¥11Êúà**
